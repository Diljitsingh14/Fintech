{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f103b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeetc\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\projections\\__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from ta import add_all_ta_features\n",
    "from ta.utils import dropna\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "\n",
    "default_symbol = '^NSEI'\n",
    "default_start_date = datetime.datetime(2013, 1, 21)\n",
    "default_end_date = datetime.datetime(2024, 4, 20)\n",
    "\n",
    "\n",
    "class AI_Model():\n",
    "    def __init__(self,model_path=None,scaler_path=None,symbol=default_symbol,start_date=default_start_date,end_date=default_end_date,verbose=True,last_trained_date=None):\n",
    "        self.symbol = symbol\n",
    "        self.start = start_date\n",
    "        self.end = end_date\n",
    "        self.data = []\n",
    "        self.is_data_loaded = False\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.future_days = 7\n",
    "        self.sequence_length = 21  # Train upto last sequence_len days\n",
    "        self.batch_size = 16  # batch size len / batch_size feed at a time \n",
    "        self.target_col = 'Open' # need to predict \n",
    "        self.model = None\n",
    "        self.is_model_loaded = False\n",
    "        self.model_path = model_path\n",
    "        self.verbose = verbose\n",
    "        self.input_shape = 92\n",
    "        self.is_model_pre_train= False\n",
    "        self.last_trained_date = last_trained_date\n",
    "        self.scaler_path = scaler_path\n",
    "        \n",
    "        if(model_path and scaler_path):\n",
    "            self.load_model()\n",
    "        else:\n",
    "            self.build_model()\n",
    "\n",
    "    def log(self,message):\n",
    "        if(self.verbose):\n",
    "            print(message)\n",
    "\n",
    "    def build_model(self):\n",
    "        self.model = keras.models.Sequential([\n",
    "        keras.layers.LSTM(512,input_shape=[None,self.input_shape]),\n",
    "        keras.layers.Dense(self.future_days)\n",
    "        ])\n",
    "\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate=0.2,momentum=0.9)\n",
    "        self.model.compile(loss=keras.losses.Huber(),optimizer=opt,metrics=['mae'])\n",
    "        self.is_model_loaded = True\n",
    "\n",
    "    def load_model(self):\n",
    "        try:\n",
    "            self.model = keras.models.load_model(self.model_path)\n",
    "            self.is_model_loaded = True\n",
    "            self.log(\"Model Loaded Successfully\")\n",
    "            self.is_model_pre_train = True\n",
    "            self.scaler = joblib.load(self.scaler_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.log(\"Failed to load Model error : \")\n",
    "            print(e)\n",
    "            self.is_model_loaded = False\n",
    "\n",
    "    def ahead_timeseries_from_array(self,data):\n",
    "        ahead_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "                    data,\n",
    "                    targets=None,\n",
    "                    sequence_length=self.sequence_length+self.future_days,\n",
    "                    batch_size=self.batch_size\n",
    "        ).map(self.split_input_and_target)\n",
    "\n",
    "        return ahead_ds\n",
    "\n",
    "    # Function to fetch historical data for a symbol\n",
    "    def fetch_data(self,start_date,end_data):\n",
    "        data = yf.download(self.symbol, start=start_date, end=end_data)\n",
    "        if(len(data)>0):\n",
    "            self.is_data_loaded = True\n",
    "            self.data = data\n",
    "\n",
    "    def fetch_latest_data(self,from_date=None):\n",
    "        # Fetch data for the latest date\n",
    "        start_date = from_date\n",
    "        if not start_date:\n",
    "            start_date = self.start\n",
    "        latest_date = datetime.datetime.now() - datetime.timedelta(days=1)\n",
    "        latest_data = self.fetch_data(start_date=start_date,end_data=latest_date)  # Replace 'NIFTY' with your desired symbol\n",
    "        # latest_data = latest_data[:latest_date]\n",
    "        return latest_data\n",
    "\n",
    "    def preprocess_data(self,data_df):\n",
    "        # Add technical analysis features\n",
    "        data_df = dropna(data_df)\n",
    "\n",
    "        data_ta = add_all_ta_features(data_df, open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume='Volume', fillna=True)\n",
    "        \n",
    "        # Scale the data\n",
    "        scaled_data = pd.DataFrame(self.scaler.fit_transform(data_ta), index=data_ta.index, columns=data_ta.columns)\n",
    "        joblib.dump(self.scaler, 'scaler.pkl')\n",
    "        \n",
    "        return scaled_data\n",
    "\n",
    "    def split_input_and_target(self,ds, ahead=7, target_col=0):\n",
    "        return ds[:, :-ahead], ds[:, -ahead:, target_col]\n",
    "\n",
    "    def train_model(self, train_data,validation_data=None, epochs=100,momentum=0.9,learning_rate=0.2,opt=None,loss=None,patience=5,moniter='mae',is_save=False):\n",
    "        if not opt:\n",
    "            opt = tf.keras.optimizers.SGD(learning_rate=0.2, momentum=0.9)\n",
    "        if not loss:\n",
    "            loss = keras.losses.Huber()\n",
    "        self.model.compile(loss=loss, optimizer=opt, metrics=['mae'])\n",
    "        if(validation_data):\n",
    "            moniter='val_loss'\n",
    "        early_stopping = keras.callbacks.EarlyStopping(patience=patience,monitor=moniter)\n",
    "        hist = self.model.fit(train_data, epochs=epochs, callbacks=[early_stopping],validation_data=validation_data)\n",
    "        \n",
    "#         Save the trained model\n",
    "        if(is_save):\n",
    "            self.model.save('trained_model-latest.h5')\n",
    "        self.hist = hist\n",
    "        self.is_model_pre_train = True\n",
    "        \n",
    "        return hist\n",
    "\n",
    "    def predict_future_prices(self,test_data):\n",
    "        # Make predictions\n",
    "        if(self.is_model_loaded and self.is_model_pre_train):\n",
    "            predictions = self.model.predict(test_data)\n",
    "            return predictions\n",
    "        self.log(\"Model is Not Loaded please load the model first.\")\n",
    "\n",
    "    def inverse_preprocess(self,data):\n",
    "        return self.scaler.inverse_transform(data)\n",
    "\n",
    "    def numpy_to_df(self,data,index,cols):\n",
    "        return pd.DataFrame(data,index=index,columns=cols)\n",
    "\n",
    "    def preprocess_in_pipe(self):\n",
    "        if(self.is_model_pre_train and self.last_trained_date):\n",
    "            fetch_latest_data()\n",
    "            \n",
    "    def pred_df_from_dummy_inverse(self,y_pred):\n",
    "        length = len(y_pred)\n",
    "        try:\n",
    "            dummy_df = pd.read_csv('dummy_for_inverse.csv',index_col='Date')[-length:]\n",
    "            dummy_df['Open'] = y_pred\n",
    "            i_ds = self.inverse_preprocess(dummy_df)\n",
    "            return i_ds[:,0]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d93855c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = AI_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd5f59fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeetc\\miniconda3\\envs\\aml1114\\lib\\site-packages\\yfinance\\utils.py:775: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
      "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "rnn_model.fetch_latest_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f7bde8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.data.iloc[-20:]['Open'].to_json(\"till_now.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfec068f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeetc\\miniconda3\\envs\\aml1114\\lib\\site-packages\\ta\\trend.py:1030: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  self._psar[i] = high2\n"
     ]
    }
   ],
   "source": [
    "preprocessed_data = rnn_model.preprocess_data(rnn_model.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf8f69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = preprocessed_data[:'2024-04-20']\n",
    "val_df = preprocessed_data['2023-12-31':'2024-04-01']\n",
    "test_df = preprocessed_data['2024-04-01':]\n",
    "\n",
    "train_ds = rnn_model.ahead_timeseries_from_array(train_df)\n",
    "val_ds = rnn_model.ahead_timeseries_from_array(val_df)\n",
    "test_ds = rnn_model.ahead_timeseries_from_array(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91ec74f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "170/170 [==============================] - 5s 23ms/step - loss: 0.0060 - mae: 0.0838\n",
      "Epoch 2/100\n",
      "170/170 [==============================] - 4s 23ms/step - loss: 0.0050 - mae: 0.0671\n",
      "Epoch 3/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 0.0049 - mae: 0.0635\n",
      "Epoch 4/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 0.0053 - mae: 0.0588\n",
      "Epoch 5/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 0.0045 - mae: 0.0605\n",
      "Epoch 6/100\n",
      "170/170 [==============================] - 4s 25ms/step - loss: 0.0035 - mae: 0.0546\n",
      "Epoch 7/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 0.0037 - mae: 0.0533\n",
      "Epoch 8/100\n",
      "170/170 [==============================] - 4s 23ms/step - loss: 0.0033 - mae: 0.0540\n",
      "Epoch 9/100\n",
      "170/170 [==============================] - 4s 23ms/step - loss: 0.0028 - mae: 0.0493\n",
      "Epoch 10/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 0.0027 - mae: 0.0474\n",
      "Epoch 11/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 0.0027 - mae: 0.0480\n",
      "Epoch 12/100\n",
      "170/170 [==============================] - 4s 23ms/step - loss: 0.0021 - mae: 0.0423\n",
      "Epoch 13/100\n",
      "170/170 [==============================] - 4s 23ms/step - loss: 0.0020 - mae: 0.0429\n",
      "Epoch 14/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 0.0017 - mae: 0.0378\n",
      "Epoch 15/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 0.0016 - mae: 0.0379\n",
      "Epoch 16/100\n",
      "170/170 [==============================] - 4s 23ms/step - loss: 0.0014 - mae: 0.0346\n",
      "Epoch 17/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 0.0013 - mae: 0.0329\n",
      "Epoch 18/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 0.0011 - mae: 0.0314\n",
      "Epoch 19/100\n",
      "170/170 [==============================] - 4s 23ms/step - loss: 9.4140e-04 - mae: 0.0292\n",
      "Epoch 20/100\n",
      "170/170 [==============================] - 4s 23ms/step - loss: 7.9757e-04 - mae: 0.0275\n",
      "Epoch 21/100\n",
      "170/170 [==============================] - 4s 25ms/step - loss: 6.7239e-04 - mae: 0.0257\n",
      "Epoch 22/100\n",
      "170/170 [==============================] - 4s 26ms/step - loss: 5.6497e-04 - mae: 0.0240\n",
      "Epoch 23/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 4.9371e-04 - mae: 0.0228\n",
      "Epoch 24/100\n",
      "170/170 [==============================] - 4s 25ms/step - loss: 4.4269e-04 - mae: 0.0218\n",
      "Epoch 25/100\n",
      "170/170 [==============================] - 4s 25ms/step - loss: 4.0620e-04 - mae: 0.0210\n",
      "Epoch 26/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 3.7849e-04 - mae: 0.0204\n",
      "Epoch 27/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 3.5683e-04 - mae: 0.0199\n",
      "Epoch 28/100\n",
      "170/170 [==============================] - 4s 25ms/step - loss: 3.3955e-04 - mae: 0.0195\n",
      "Epoch 29/100\n",
      "170/170 [==============================] - 4s 25ms/step - loss: 3.2553e-04 - mae: 0.0192\n",
      "Epoch 30/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 3.1396e-04 - mae: 0.0189\n",
      "Epoch 31/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 3.0426e-04 - mae: 0.0186\n",
      "Epoch 32/100\n",
      "170/170 [==============================] - 4s 25ms/step - loss: 2.9596e-04 - mae: 0.0184\n",
      "Epoch 33/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 2.8869e-04 - mae: 0.0181\n",
      "Epoch 34/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 2.8211e-04 - mae: 0.0179\n",
      "Epoch 35/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 2.7595e-04 - mae: 0.0177\n",
      "Epoch 36/100\n",
      "170/170 [==============================] - 4s 25ms/step - loss: 2.7001e-04 - mae: 0.0175\n",
      "Epoch 37/100\n",
      "170/170 [==============================] - 4s 25ms/step - loss: 2.6422e-04 - mae: 0.0173\n",
      "Epoch 38/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 2.5858e-04 - mae: 0.0171\n",
      "Epoch 39/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 2.5318e-04 - mae: 0.0169\n",
      "Epoch 40/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 2.4810e-04 - mae: 0.0167\n",
      "Epoch 41/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 2.4342e-04 - mae: 0.0165\n",
      "Epoch 42/100\n",
      "170/170 [==============================] - 4s 25ms/step - loss: 2.3915e-04 - mae: 0.0163\n",
      "Epoch 43/100\n",
      "170/170 [==============================] - 4s 23ms/step - loss: 2.3528e-04 - mae: 0.0162\n",
      "Epoch 44/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 2.3177e-04 - mae: 0.0160\n",
      "Epoch 45/100\n",
      "170/170 [==============================] - 4s 25ms/step - loss: 2.2857e-04 - mae: 0.0159\n",
      "Epoch 46/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 2.2564e-04 - mae: 0.0157\n",
      "Epoch 47/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 2.2294e-04 - mae: 0.0156\n",
      "Epoch 48/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 2.2043e-04 - mae: 0.0155\n",
      "Epoch 49/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 2.1808e-04 - mae: 0.0154\n",
      "Epoch 50/100\n",
      "170/170 [==============================] - 4s 25ms/step - loss: 2.1586e-04 - mae: 0.0153\n",
      "Epoch 51/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 2.1373e-04 - mae: 0.0152\n",
      "Epoch 52/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 2.1168e-04 - mae: 0.0151\n",
      "Epoch 53/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 2.0968e-04 - mae: 0.0150\n",
      "Epoch 54/100\n",
      "170/170 [==============================] - 4s 25ms/step - loss: 2.0771e-04 - mae: 0.0149\n",
      "Epoch 55/100\n",
      "170/170 [==============================] - 4s 25ms/step - loss: 2.0575e-04 - mae: 0.0148\n",
      "Epoch 56/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 2.0379e-04 - mae: 0.0147\n",
      "Epoch 57/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 2.0181e-04 - mae: 0.0146\n",
      "Epoch 58/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 1.9982e-04 - mae: 0.0146\n",
      "Epoch 59/100\n",
      "170/170 [==============================] - 4s 26ms/step - loss: 1.9780e-04 - mae: 0.0145\n",
      "Epoch 60/100\n",
      "170/170 [==============================] - 4s 26ms/step - loss: 1.9575e-04 - mae: 0.0144\n",
      "Epoch 61/100\n",
      "170/170 [==============================] - 5s 27ms/step - loss: 1.9369e-04 - mae: 0.0143\n",
      "Epoch 62/100\n",
      "170/170 [==============================] - 4s 26ms/step - loss: 1.9160e-04 - mae: 0.0142\n",
      "Epoch 63/100\n",
      "170/170 [==============================] - 5s 27ms/step - loss: 1.8950e-04 - mae: 0.0141\n",
      "Epoch 64/100\n",
      "170/170 [==============================] - 4s 26ms/step - loss: 1.8739e-04 - mae: 0.0140\n",
      "Epoch 65/100\n",
      "170/170 [==============================] - 5s 27ms/step - loss: 1.8528e-04 - mae: 0.0139\n",
      "Epoch 66/100\n",
      "170/170 [==============================] - 4s 26ms/step - loss: 1.8318e-04 - mae: 0.0138\n",
      "Epoch 67/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 1.8110e-04 - mae: 0.0137\n",
      "Epoch 68/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 1.7905e-04 - mae: 0.0136\n",
      "Epoch 69/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 1.7703e-04 - mae: 0.0136\n",
      "Epoch 70/100\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 1.7506e-04 - mae: 0.0135\n",
      "Epoch 71/100\n",
      "170/170 [==============================] - 4s 26ms/step - loss: 1.7314e-04 - mae: 0.0134\n",
      "Epoch 72/100\n",
      "170/170 [==============================] - 4s 25ms/step - loss: 1.7129e-04 - mae: 0.0133\n",
      "Epoch 73/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 1.6952e-04 - mae: 0.0133\n",
      "Epoch 74/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 1.6783e-04 - mae: 0.0132\n",
      "Epoch 75/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 1.6624e-04 - mae: 0.0131\n",
      "Epoch 76/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 1.6475e-04 - mae: 0.0131\n",
      "Epoch 77/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 1.6337e-04 - mae: 0.0130\n",
      "Epoch 78/100\n",
      "170/170 [==============================] - 4s 25ms/step - loss: 1.6210e-04 - mae: 0.0130\n",
      "Epoch 79/100\n",
      "170/170 [==============================] - 4s 25ms/step - loss: 1.6097e-04 - mae: 0.0130\n",
      "Epoch 80/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 1.5999e-04 - mae: 0.0130\n",
      "Epoch 81/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 1.5917e-04 - mae: 0.0129\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 4s 25ms/step - loss: 1.5857e-04 - mae: 0.0129\n",
      "Epoch 83/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 1.5822e-04 - mae: 0.0129\n",
      "Epoch 84/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 1.5816e-04 - mae: 0.0130\n",
      "Epoch 85/100\n",
      "170/170 [==============================] - 4s 25ms/step - loss: 1.5840e-04 - mae: 0.0130\n",
      "Epoch 86/100\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 1.5888e-04 - mae: 0.0130\n",
      "Epoch 87/100\n",
      "170/170 [==============================] - 4s 25ms/step - loss: 1.5954e-04 - mae: 0.0131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e6e58c0670>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ds = rnn_model.ahead_timeseries_from_array(preprocessed_data)\n",
    "rnn_model.train_model(full_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "114fed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.model.save('trained_model-latest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2d9f730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler-latest.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rnn_model.scaler, 'scaler-latest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a248bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 317ms/step\n"
     ]
    }
   ],
   "source": [
    "# test_df = preprocessed_data['2024-04-01':]\n",
    "X = preprocessed_data[-rnn_model.sequence_length:].to_numpy()[np.newaxis,:rnn_model.sequence_length]\n",
    "y_pred = rnn_model.predict_future_prices(X)\n",
    "predictions = rnn_model.pred_df_from_dummy_inverse(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d9f314c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22280.78154657, 22261.86345068, 22367.22545753, 22398.21606567,\n",
       "       22545.60980975, 22504.12041078, 22553.29450248])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions-350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3568ef89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 21, 92)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8068f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"x_df.json\",'w') as fp:\n",
    "    json.dump(X.tolist(),fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.train_model(train_ds,val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6090c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_df.to_numpy()[np.newaxis,:rnn_model.sequence_length]\n",
    "y_pred = rnn_model.predict_future_prices(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d36f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = test_df.copy()\n",
    "tdf['Open'][:rnn_model.future_days] = y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6cc808",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_ds = rnn_model.inverse_preprocess(tdf)\n",
    "i_df = rnn_model.numpy_to_df(i_ds,tdf.index,tdf.columns)\n",
    "i_test_ds = rnn_model.inverse_preprocess(test_df)\n",
    "i_test_df = rnn_model.numpy_to_df(i_test_ds,test_df.index,test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9d48f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "i_df[:rnn_model.future_days]['Open'].plot(label='Predicted', marker='o',style='--')\n",
    "i_test_df[:rnn_model.future_days]['Open'].plot(label='Actual', marker='o',style='--')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Open Price')\n",
    "plt.title('Comparison between Predicted and Actual Open Prices')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a720af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"dummy_for_inverse.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be218187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scaler\n",
    "joblib.dump(rnn_model.scaler, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51906b77",
   "metadata": {},
   "source": [
    "### PreTrain load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587beb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_trained_date = datetime.datetime(2024, 2, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b6fcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_nn_model = AI_Model(model_path='trained_model.h5',scaler_path='scaler.pkl')\n",
    "X = test_df[-pre_nn_model.sequence_length:].to_numpy()[np.newaxis,:pre_nn_model.sequence_length]\n",
    "y_pred = pre_nn_model.predict_future_prices(X)\n",
    "predictions = pre_nn_model.pred_df_from_dummy_inverse(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a12381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "\n",
    "actual = pre_nn_model.pred_df_from_dummy_inverse(test_df['Open'][-7:].to_numpy())\n",
    "sn.lineplot(predictions)\n",
    "sn.lineplot(actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078fd0b3",
   "metadata": {},
   "source": [
    "### with with fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6549f7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AI_Model(model_path='trained_model.h5',scaler_path='scaler.pkl')\n",
    "base_model = AI_Model()\n",
    "\n",
    "# X = test_df[-pre_nn_model.sequence_length:].to_numpy()[np.newaxis,:pre_nn_model.sequence_length]\n",
    "# y_pred = pre_nn_model.predict_future_prices(X)\n",
    "# predictions = pre_nn_model.pred_df_from_dummy_inverse(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e03b491",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.fetch_latest_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062ba97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.model.compile(loss=keras.losses.Hinge(),optimizer='adam',metrics=['mae'])\n",
    "base_model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77bccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = base_model.preprocess_data(base_model.data)\n",
    "train_ds = base_model.ahead_timeseries_from_array(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37b5453",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.train_model(train_ds,val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a90905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(base_model.hist.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8b7aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess[-base_model.sequence_length:].to_numpy()[np.newaxis,:pre_nn_model.sequence_length]\n",
    "# y_pred = base_model.predict_future_prices(X)\n",
    "predictions= base_model.predict_future_prices(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551652ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "\n",
    "actual = base_model.pred_df_from_dummy_inverse(test_df['Open'][-7:].to_numpy())\n",
    "preds = pre_nn_model.pred_df_from_dummy_inverse(predictions[0])\n",
    "\n",
    "# Convert preds and actual to pandas Series objects\n",
    "preds_series = pd.Series(preds, index=range(len(preds)))\n",
    "actual_series = pd.Series(actual, index=range(len(actual)))\n",
    "\n",
    "# Plot the predicted and actual prices\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the predicted prices with custom style\n",
    "sns.lineplot(data=preds_series, label='Predicted', marker='o', linestyle='--')\n",
    "\n",
    "# Plot the actual prices with custom style\n",
    "sns.lineplot(data=actual_series, label='Actual', marker='o', linestyle='--')\n",
    "\n",
    "# Add annotations for maximum and minimum predicted prices\n",
    "max_pred_price = preds_series.max()\n",
    "min_pred_price = preds_series.min()\n",
    "\n",
    "max_x, max_y = preds_series.idxmax(), max_pred_price\n",
    "min_x, min_y = preds_series.idxmin(), min_pred_price\n",
    "\n",
    "# Adjust annotation position if it exceeds y-axis limits\n",
    "if max_y > plt.gca().get_ylim()[1]:\n",
    "    max_y = plt.gca().get_ylim()[1]\n",
    "if min_y < plt.gca().get_ylim()[0]:\n",
    "    min_y = plt.gca().get_ylim()[0]\n",
    "\n",
    "plt.annotate(f'Max Predicted Price: {max_pred_price:.2f}', xy=(max_x, max_y-40), xytext=(max_x+.1, max_y - 150),\n",
    "             arrowprops=dict(facecolor='green', shrink=0.05))\n",
    "\n",
    "plt.annotate(f'Min Predicted Price: {min_pred_price:.2f}', xy=(min_x, min_y+40), xytext=(min_x-.1, min_y + 140),\n",
    "             arrowprops=dict(facecolor='red', shrink=0.1))\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Comparison between Predicted and Actual Prices')\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09687cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d6813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install optionlab --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fddb701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optionlab import run_strategy\n",
    "\n",
    "yield_rate = 7.179\n",
    "inflation = 4.85\n",
    "\n",
    "inputs_data = {\n",
    "    'country':'India',\n",
    "    \"stock_price\": 22519,\n",
    "    \"start_date\": \"2024-04-12\",\n",
    "    \"target_date\": \"2024-04-18\",\n",
    "    \"volatility\": 0.1153,\n",
    "    \"interest_rate\": 0.0002,\n",
    "    \"min_stock\": 22068.1,\n",
    "    \"max_stock\": 23460,\n",
    "    \"strategy\": [\n",
    "        {\"type\": \"call\", \"strike\": 22800, \"premium\": 34.80, \"n\": 50, \"action\": \"sell\"},\n",
    "        {\"type\": \"put\", \"strike\": 22150, \"premium\": 15.20, \"n\": 50, \"action\": \"sell\"},\n",
    "        \n",
    "    ],\n",
    "}\n",
    "\n",
    "out = run_strategy(inputs_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04daadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Probability of Profit (PoP): %.1f%%\" % (out.probability_of_profit * 100.0)) # 74.5%, according to the calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49903179",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.strategy_cost,out.minimum_return_in_the_domain,out.maximum_return_in_the_domain,out.in_the_money_probability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
